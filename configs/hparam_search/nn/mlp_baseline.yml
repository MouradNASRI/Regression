name: "mlp_baseline"
model: "mlp"
metric: "mse"
mode: "min"
strategy: "grid"

base_model_params:
  solver: "adam"
  max_iter: 500
  random_state: 42
  early_stopping: true
  validation_fraction: 0.1
  tol: 0.0001

params:
  hidden_layer_sizes:
    - [50]
    - [100]
    - [100, 50]
  activation: ["relu", "tanh"]
  alpha: [0.0001, 0.001, 0.01]
  learning_rate_init: [0.001, 0.01]
