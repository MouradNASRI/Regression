model:
  name: "hist_gradient_boosting_regression"
  library: "sklearn"
  type: "hgb"
  params:
    # HistGradientBoostingRegressor(**params)
    loss: "squared_error"       # can also be "absolute_error","poisson","gamma","tweedie"
    learning_rate: 0.1
    max_depth: null             # or int
    max_leaf_nodes: 31
    min_samples_leaf: 20
    l2_regularization: 0.0
    max_bins: 255
    categorical_features: null  # handled by your preprocessing anyway
    monotonic_cst: null
    interaction_cst: null
    max_iter: 100
    min_samples_leaf: 20
    tol: 1e-7
    scoring: null
    validation_fraction: 0.1
    n_iter_no_change: 10
    random_state: 42
    verbose: 0
    warm_start: false

preprocessing:
  # HGB is tree-based, no need for scaling
  scale_numeric: false

collinearity:
  # Tree-based GBM is robust to collinearity â†’ no reduction
  enabled: false

mlflow:
  log_collinearity_diagnostics: false
  log_vif_table: false
  log_correlation_heatmap: false
  log_svd_spectrum: false
