model:
  name: "mlp_regression"
  library: "sklearn"
  type: "mlp"
  params:
    # MLPRegressor(**params)
    hidden_layer_sizes: [100]   # single hidden layer with 100 units
    activation: "relu"          # "identity","logistic","tanh","relu"
    solver: "adam"              # "lbfgs","sgd","adam"
    alpha: 0.0001               # L2 penalty
    batch_size: "auto"
    learning_rate: "constant"   # "constant","invscaling","adaptive"
    learning_rate_init: 0.001
    power_t: 0.5
    max_iter: 200
    shuffle: true
    random_state: 42
    tol: 0.0001
    verbose: false
    warm_start: false
    momentum: 0.9
    nesterovs_momentum: true
    early_stopping: false
    validation_fraction: 0.1
    beta_1: 0.9
    beta_2: 0.999
    epsilon: 1e-8
    n_iter_no_change: 10
    max_fun: 15000

preprocessing:
  # Neural nets are very sensitive to scale
  scale_numeric: true

collinearity:
  enabled: true
  mode: "manual"

  # Collinearity isn't fatal for MLP, but redundant inputs
  # can slow optimization. Keep a *very* gentle Pearson pass.
  pipeline: ["pearson"]

  pearson:
    abs_threshold: 0.99

  vif:
    threshold: 10.0
    max_iter: 10

  svd:
    action: "warn"
    tiny_singular_value_threshold: 1e-6

  condition_number:
    threshold: 30.0

mlflow:
  log_collinearity_diagnostics: true
  log_vif_table: true
  log_correlation_heatmap: false
  log_svd_spectrum: false
